"""
OHLCV ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ (Phase 2)
"""

import time
from multiprocessing import Pool

import pandas as pd

from pykrx import stock

from .config import Config
from .progress_tracker import ProgressTracker
from .storage import StorageManager
from .utils import date_to_string, retry_with_backoff, split_date_range_by_year


class OHLCVCollector:
    """OHLCV ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤"""

    def __init__(self, progress_tracker: ProgressTracker, storage: StorageManager):
        """OHLCV ìˆ˜ì§‘ ì´ˆê¸°í™”"""

        self.progress_tracker = progress_tracker
        self.storage = storage

    def collect_all_ohlcv(self, use_multiprocessing: bool = True):
        """ì „ì²´ OHLCV ë°ì´í„° ìˆ˜ì§‘"""

        print("\nğŸ“Š Phase 2: OHLCV ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")

        # ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘ì¸ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        pending_tickers = self.progress_tracker.get_pending_tickers()
        if not pending_tickers:
            # ProgressTrackerì—ì„œ ëª¨ë“  í‹°ì»¤ ê°€ì ¸ì˜¤ê¸°
            all_tickers = list(self.progress_tracker.progress.get("tickers", {}).keys())
            pending_tickers = [
                t for t in all_tickers if not self.progress_tracker.is_ticker_collected(t)
            ]

        if not pending_tickers:
            print("  âœ… ìˆ˜ì§‘í•  í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"  ì´ {len(pending_tickers)}ê°œ í‹°ì»¤ ìˆ˜ì§‘ ì˜ˆì •")

        if use_multiprocessing and Config.MAX_WORKERS > 1:
            self._collect_with_multiprocessing(pending_tickers)
        else:
            self._collect_sequential(pending_tickers)

        # ìµœì¢… í†µê³„
        stats = self.progress_tracker.get_stats()
        print("\n  âœ… OHLCV ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"    - ì™„ë£Œ: {stats.get('completed_tickers', 0)}ê°œ")
        print(f"    - ì‹¤íŒ¨: {stats.get('failed_tickers', 0)}ê°œ")
        print(f"    - ì „ì²´: {stats.get('total_tickers', 0)}ê°œ")

    def _collect_sequential(self, tickers: list[str]):
        """ìˆœì°¨ì ìœ¼ë¡œ OHLCV ë°ì´í„° ìˆ˜ì§‘"""

        total = len(tickers)
        for i, ticker in enumerate(tickers, 1):
            print(f"\n  [{i}/{total}] í‹°ì»¤: {ticker}")
            self._collect_ticker_ohlcv(ticker)
            time.sleep(Config.REQUEST_DELAY)

    def _collect_with_multiprocessing(self, tickers: list[str]):
        """ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ OHLCV ë°ì´í„° ìˆ˜ì§‘"""

        print(f"  ë©€í‹°í”„ë¡œì„¸ì‹± ëª¨ë“œ (ì›Œì»¤: {Config.MAX_WORKERS}, ì´ {len(tickers)}ê°œ í‹°ì»¤)")

        # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
        batch_size = Config.BATCH_SIZE
        batches = [tickers[i : i + batch_size] for i in range(0, len(tickers), batch_size)]

        for batch_num, batch in enumerate(batches, 1):
            print(f"\n  ë°°ì¹˜ {batch_num}/{len(batches)} ({len(batch)}ê°œ í‹°ì»¤)")

            with Pool(processes=Config.MAX_WORKERS) as pool:
                results = pool.map(self._collect_ticker_ohlcv_wrapper, batch)

            # ê²°ê³¼ ìš”ì•½
            completed = sum(1 for r in results if r is True)
            failed = sum(1 for r in results if r is False)
            print(f"    ì™„ë£Œ: {completed}, ì‹¤íŒ¨: {failed}")

            time.sleep(Config.REQUEST_DELAY * 2)  # ë°°ì¹˜ ê°„ ë”œë ˆì´

    @staticmethod
    def _collect_ticker_ohlcv_wrapper(ticker: str) -> bool:
        """ë©€í‹°í”„ë¡œì„¸ì‹±ìš© ë˜í¼ í•¨ìˆ˜"""

        # ê° í”„ë¡œì„¸ìŠ¤ì—ì„œ ìƒˆë¡œìš´ StorageManagerì™€ ProgressTracker ìƒì„±
        from .progress_tracker import ProgressTracker
        from .storage import StorageManager

        progress_tracker = ProgressTracker()
        storage = StorageManager()

        try:
            collector = OHLCVCollector(progress_tracker, storage)
            collector._collect_ticker_ohlcv(ticker)
            storage.close()
            return True
        except Exception as e:
            print(f"  âš ï¸  í‹°ì»¤ {ticker} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            progress_tracker.mark_ticker_failed(ticker, str(e))
            storage.close()
            return False

    def _collect_ticker_ohlcv(self, ticker: str):
        """íŠ¹ì • í‹°ì»¤ì˜ OHLCV ë°ì´í„° ìˆ˜ì§‘ (ì—°ë„ë³„ ë¶„í• )"""

        ticker_info = self.progress_tracker.get_ticker_info(ticker)
        if not ticker_info:
            print(f"    âš ï¸  í‹°ì»¤ {ticker} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìˆ˜ì§‘ ê¸°ê°„ ê²°ì •
        listing_date = ticker_info.get("listing_date") or Config.START_DATE
        delisting_date = ticker_info.get("delisting_date")
        end_date = delisting_date if delisting_date else Config.END_DATE

        # ì´ë¯¸ ìˆ˜ì§‘ëœ ê²½ìš° ìŠ¤í‚µ
        if self.progress_tracker.is_ticker_collected(ticker):
            last_collected = ticker_info.get("last_collected_date")
            if last_collected and last_collected >= end_date:
                print(f"    â­ï¸  ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œ (ë§ˆì§€ë§‰ ìˆ˜ì§‘ì¼: {last_collected})")
                return

        # ì—°ë„ë³„ë¡œ ë¶„í• 
        year_ranges = split_date_range_by_year(listing_date, end_date)
        if not year_ranges:
            print("    âš ï¸  ìœ íš¨í•œ ë‚ ì§œ ë²”ìœ„ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"    ğŸ“… {len(year_ranges)}ê°œ ì—°ë„ ë¶„í•  ìˆ˜ì§‘: {listing_date} ~ {end_date}")

        all_dataframes = []
        failed_years = []

        try:
            # ì—°ë„ë³„ë¡œ ë°ì´í„° ìˆ˜ì§‘
            for year_start, year_end in year_ranges:
                year = year_start[:4]
                try:
                    print(f"      [{year}] {year_start} ~ {year_end} ìˆ˜ì§‘ ì¤‘...")
                    df_year = self._fetch_ohlcv_data(ticker, year_start, year_end)

                    if not df_year.empty:
                        all_dataframes.append(df_year)
                        print(f"      [{year}] âœ… {len(df_year)}ì¼ ìˆ˜ì§‘ ì™„ë£Œ")
                    else:
                        print(f"      [{year}] âš ï¸  ë°ì´í„° ì—†ìŒ")
                        failed_years.append(year)

                    # ì—°ë„ ê°„ ë”œë ˆì´
                    time.sleep(Config.REQUEST_DELAY)

                except Exception as e:
                    print(f"      [{year}] âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    failed_years.append(year)

            # ëª¨ë“  ì—°ë„ ë°ì´í„° í•©ì¹˜ê¸°
            if not all_dataframes:
                error_msg = (
                    f"ëª¨ë“  ì—°ë„ ìˆ˜ì§‘ ì‹¤íŒ¨ (ì‹¤íŒ¨ ì—°ë„: {', '.join(failed_years)})"
                    if failed_years
                    else "ë°ì´í„° ì—†ìŒ"
                )
                print(f"    âš ï¸  {error_msg}")
                self.progress_tracker.mark_ticker_failed(ticker, error_msg)
                return

            # DataFrame í•©ì¹˜ê¸°
            df = pd.concat(all_dataframes, ignore_index=False)
            df = df.sort_index() if hasattr(df, "sort_index") else df.sort_values("date")
            # ì¤‘ë³µ ì œê±° (ì—°ë„ ê²½ê³„ì—ì„œ ì¤‘ë³µ ê°€ëŠ¥)
            df = df.drop_duplicates(subset=["date"] if "date" in df.columns else None, keep="last")

            if df.empty:
                print("    âš ï¸  í•©ì¹œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                self.progress_tracker.mark_ticker_failed(ticker, "í•©ì¹œ ë°ì´í„° ì—†ìŒ")
                return

            # ë°ì´í„° ì €ì¥
            market = ticker_info.get("market", "UNKNOWN")
            self._save_ticker_data(df, ticker, market)

            # ì™„ë£Œ í‘œì‹œ
            last_date = df["date"].max() if "date" in df.columns else df.index.max()

            # Timestampë¡œ ë³€í™˜ ë³´ì¥
            try:
                if isinstance(last_date, pd.Timestamp) and last_date is not pd.NaT:
                    last_date_str = date_to_string(last_date)
                elif isinstance(last_date, pd.Series) and len(last_date) > 0:
                    last_date_val = last_date.iloc[0]
                    if isinstance(last_date_val, pd.Timestamp) and last_date_val is not pd.NaT:
                        last_date_str = date_to_string(last_date_val)
                    else:
                        last_date_str = Config.END_DATE
                else:
                    # ìµœí›„ì˜ ìˆ˜ë‹¨: ë§ˆì§€ë§‰ í–‰ì˜ ë‚ ì§œ ì‚¬ìš©
                    last_date_val = df["date"].iloc[-1] if "date" in df.columns else df.index[-1]
                    if isinstance(last_date_val, pd.Timestamp) and last_date_val is not pd.NaT:
                        last_date_str = date_to_string(last_date_val)
                    else:
                        last_date_str = Config.END_DATE
            except Exception:
                last_date_str = Config.END_DATE

            self.progress_tracker.mark_ticker_completed(ticker, last_date_str)

            total_days = len(df)
            first_date = df["date"].min() if "date" in df.columns else df.index.min()
            last_date_display = df["date"].max() if "date" in df.columns else df.index.max()
            print(f"    âœ… ìˆ˜ì§‘ ì™„ë£Œ: {total_days}ì¼ ({first_date} ~ {last_date_display})")
            if failed_years:
                print(f"    âš ï¸  ì¼ë¶€ ì—°ë„ ì‹¤íŒ¨: {', '.join(failed_years)}")

        except Exception as e:
            print(f"    âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            self.progress_tracker.mark_ticker_failed(ticker, str(e))

    @retry_with_backoff(max_retries=Config.MAX_RETRIES, delay=Config.RETRY_DELAY)
    def _fetch_ohlcv_data(self, ticker: str, fromdate: str, todate: str) -> pd.DataFrame:
        """OHLCV ë°ì´í„° ì¡°íšŒ"""

        try:
            df = stock.get_market_ohlcv_by_date(
                fromdate=fromdate,
                todate=todate,
                ticker=ticker,
                adjusted=Config.ADJUSTED,
            )

            if df.empty:
                return df

            # ticker ì»¬ëŸ¼ ì¶”ê°€
            df["ticker"] = ticker
            # date ì»¬ëŸ¼ ì¶”ê°€ (ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ)
            df = df.reset_index()
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            if "ë‚ ì§œ" in df.columns:
                df["date"] = pd.to_datetime(df["ë‚ ì§œ"])
            elif "Date" in df.columns:
                df["date"] = pd.to_datetime(df["Date"])
            elif df.index.name in ["ë‚ ì§œ", "Date", "date"]:
                df["date"] = pd.to_datetime(df.index)
            else:
                # ì¸ë±ìŠ¤ê°€ ë‚ ì§œì¸ ê²½ìš°
                df["date"] = pd.to_datetime(df.index)

            return df

        except Exception as e:
            print(f"    âš ï¸  OHLCV ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def _save_ticker_data(self, df: pd.DataFrame, ticker: str, market: str):
        """í‹°ì»¤ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì €ì¥"""

        if df.empty:
            return

        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        df["date"] = pd.to_datetime(df["date"])
        grouped = df.groupby(df["date"].dt.to_period("M"))

        saved_count = 0
        for period, group_df in grouped:
            # Periodë¥¼ Timestampë¡œ ë³€í™˜
            try:
                if isinstance(period, pd.Period):
                    date = period.to_timestamp()
                else:
                    # Period ê°ì²´ê°€ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ íŒŒì‹±
                    date = pd.Timestamp(str(period))
            except Exception:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ì²« ë²ˆì§¸ ë‚ ì§œ ì‚¬ìš©
                date = group_df["date"].iloc[0] if not group_df.empty else pd.Timestamp.now()
            # ticker ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
            if "ticker" not in group_df.columns:
                group_df["ticker"] = ticker

            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            columns = ["date", "ticker", "ì‹œê°€", "ê³ ê°€", "ì €ê°€", "ì¢…ê°€", "ê±°ë˜ëŸ‰"]
            group_df = group_df[columns].copy()

            # ì €ì¥ (DataFrame í™•ì¸)
            if isinstance(group_df, pd.DataFrame):
                # dateê°€ ìœ íš¨í•œ Timestampì¸ì§€ í™•ì¸
                if isinstance(date, pd.Timestamp) and not pd.isna(date):
                    self.storage.save_ohlcv_data(group_df, market, date)
                    saved_count += 1
                else:
                    print(f"    âš ï¸  ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ë¡œ ìŠ¤í‚µ: {date}")

        if saved_count > 0:
            print(f"    ğŸ’¾ {saved_count}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
